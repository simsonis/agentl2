"""
Simple FastAPI server for testing Agent flow.
"""

import asyncio
import json
from typing import Dict, Any, AsyncGenerator, List

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import uvicorn


class ChatRequest(BaseModel):
    messages: List[Dict[str, str]]
    conversation_id: str = None


app = FastAPI(title="AgentL2 LLM Service", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


async def simulate_agent_pipeline(user_message: str) -> AsyncGenerator[str, None]:
    """Simulate the 6-step agent pipeline with streaming updates."""

    try:
        # Step 1: ì „ë‹¬ì Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'facilitator', 'step': 'ì‚¬ìš©ì ì˜ë„ íŒŒì•… ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.5)

        # Step 2: ê²€ìƒ‰ Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'search', 'step': 'ê´€ë ¨ ë²•ë ¹ ë° íŒë¡€ ê²€ìƒ‰ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.7)

        # Step 3: ë¶„ì„ê°€ Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'analyst', 'step': 'ë²•ì  ë¶„ì„ ë° ìŸì  ì‹ë³„ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.8)

        # Step 4: ì‘ë‹µ Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'response', 'step': 'ë‹µë³€ ë‚´ìš© ìƒì„± ì¤‘...'})}\n\n"
        await asyncio.sleep(0.6)

        # Step 5: ì¸ìš© Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'citation', 'step': 'ì¸ìš© ë° ì¶œì²˜ ì •ë¦¬ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.4)

        # Step 6: ê²€ì¦ì Agent
        yield f"data: {json.dumps({'type': 'agent_step', 'agent': 'validator', 'step': 'ìµœì¢… ê²€ì¦ ë° í’ˆì§ˆ í™•ì¸ ì¤‘...'})}\n\n"
        await asyncio.sleep(0.5)

        # Generate simulated response based on user message
        response_text = f"""'{user_message}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.

ğŸ” **Agent ì²´ì¸ ë¶„ì„ ê²°ê³¼:**

**1ë‹¨ê³„ (ì „ë‹¬ì)**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ë²•ì  ì˜ë„ë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.

**2ë‹¨ê³„ (ê²€ìƒ‰)**: ê´€ë ¨ ë²•ë ¹, íŒë¡€, í•´ì„ë¡€ë¥¼ ë‹¤ì¤‘ ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.

**3ë‹¨ê³„ (ë¶„ì„ê°€)**: ë²•ì  ìŸì ì„ ì‹ë³„í•˜ê³  ì ìš© ê°€ëŠ¥í•œ ë²•ë¦¬ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

**4ë‹¨ê³„ (ì‘ë‹µ)**: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

**5ë‹¨ê³„ (ì¸ìš©)**: ì°¸ì¡°ëœ ë²•ë ¹ê³¼ íŒë¡€ì˜ ì¶œì²˜ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

**6ë‹¨ê³„ (ê²€ì¦ì)**: ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ìµœì¢… í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ì´ëŠ” 6ë‹¨ê³„ Agent ì²´ì¸ì„ í†µí•´ ì²˜ë¦¬ëœ ê³ í’ˆì§ˆ ë²•ë¥  ë‹µë³€ì…ë‹ˆë‹¤."""

        # Stream the response content
        content_parts = response_text.split('. ')
        for i, part in enumerate(content_parts):
            if part.strip():
                content = part + ('. ' if i < len(content_parts) - 1 else '')
                yield f"data: {json.dumps({'type': 'content', 'content': content})}\n\n"
                await asyncio.sleep(0.1)

        # Send final response with sources
        final_data = {
            'type': 'complete',
            'final_response': {
                'answer': response_text,
                'sources': [
                    {
                        'source_name': 'ê°œì¸ì •ë³´ë³´í˜¸ë²• ì œ15ì¡°',
                        'description': 'Agent ì²´ì¸ì—ì„œ ê²€ìƒ‰ëœ ê´€ë ¨ ë²•ë ¹',
                        'link': 'https://www.law.go.kr/LSW/lsInfoP.do?lsId=008032'
                    },
                    {
                        'source_name': 'ê´€ë ¨ íŒë¡€ 2022ë‹¤12345',
                        'description': 'Agent ì²´ì¸ì—ì„œ ë¶„ì„ëœ ì°¸ì¡° íŒë¡€',
                        'link': '#'
                    }
                ],
                'followUps': [
                    'ë” êµ¬ì²´ì ì¸ ìƒí™©ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”',
                    'ê´€ë ¨ ë²•ë ¹ì˜ ì‹œí–‰ë ¹ë„ í™•ì¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤',
                    'ë¹„ìŠ·í•œ íŒë¡€ê°€ ë” ìˆëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤'
                ],
                'confidence': 0.87,
                'processing_time': 3.5
            }
        }
        yield f"data: {json.dumps(final_data)}\n\n"

    except Exception as e:
        error_data = {
            'type': 'error',
            'error': f'Agent ì²´ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
        }
        yield f"data: {json.dumps(error_data)}\n\n"


@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """Stream chat response through simulated agent pipeline."""

    # Extract user message
    user_message = ""
    for message in reversed(request.messages):
        if message.get("role") == "user":
            user_message = message.get("content", "")
            break

    if not user_message:
        raise HTTPException(status_code=400, detail="No user message found")

    return StreamingResponse(
        simulate_agent_pipeline(user_message),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream"
        }
    )


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "pipeline": {
            "type": "simulated_6_agent_pipeline",
            "status": "operational",
            "agents": {
                "facilitator": {"status": "operational", "role": "ì˜ë„íŒŒì•…/í‚¤ì›Œë“œì¶”ì¶œ"},
                "search": {"status": "operational", "role": "ë‹¤ì¤‘ë¼ìš´ë“œê²€ìƒ‰"},
                "analyst": {"status": "operational", "role": "ë²•ì ë¶„ì„/ìŸì ì‹ë³„"},
                "response": {"status": "operational", "role": "ë‹µë³€ë‚´ìš©ìƒì„±"},
                "citation": {"status": "operational", "role": "ì¸ìš©/ì¶œì²˜ê´€ë¦¬"},
                "validator": {"status": "operational", "role": "ì¢…í•©ê²€ì¦/í’ˆì§ˆê´€ë¦¬"}
            }
        }
    }


if __name__ == "__main__":
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )